\chapter{Metriky strojového překladu}
\label{chap:metrics}

Při porovnávání dvou strojových překladů je třeba,
  abychom byli schopní snadno a rychle určit,
  jak jsou jednotlivé překlady dobré.
Posuzování kvality překladů člověkem je časově náročné
  a není možné ho automatizovat.
Proto byly vytvořeny metriky,
  jejichž výsledky jsou podobné výsledkům získaným od lidí,
  ale je možné je rychle spočítat,
  aplikovat na různé jazyky a opakovat dle libosti.
Mezi tyto metriky patří i metrika BLEU,
  která byla zvolena jako výchozí metrika v~nástroji \mbox{MT-ComparEval}.

Při počítání metrik strojových překladů se zjišťuje,
  jak moc se strojový překlad podobá překladu od člověka -- tzv. referenčnímu překladu.
Čím více se podobá strojový překlad referenci,
  tím je považován za lepší.
To ovšem neznamená, že překlad s~nižší hodnotou metriky je špatný.
Překlad totiž můžeme provést několika různými způsoby 
  ( např. můžeme změnit slovosled, použít synonyma, \dots ),
  z~nichž se pouze jeden bude shodovat s~referenčním překladem.
Tento problém může zmírnit použití více referenčních překladů,
  ale úplně odstranit ho nelze.
Některé překladatelské systémy jsou optimalizovány pro určité metriky,
  avšak jejich výsledný překlad nemusí být ideální.
Proto je třeba,
  abychom se při vyhodnocování strojového překladu nespoléhalo pouze na jednu metriku.


\section{BLEU}
Nejvíce používanou metrikou pro vyhodnocování překladů je metrika BLEU.
Hlavním důvodem je to,
  že koreluje s lidským hodnocením překladu
  a je možné ji rychle spočítat.
Rychlost výpočtu metrik je pro vývojáře překladových systémů velmi důležitá,
  protože vývojáři potřebují každou změnu v~systému otestovat,
  aby si mohli být jisti,
  že překladový systém nepokazili.

Při počítání metriky BLEU počítá \textbf{modified precision} \mbox{n-gramů},
  která říká,
  kolik \mbox{n-gramů} z~vyhodnocovaného překladu se nachází i v~referenčním překladu.	
Výpočet modified precision \mbox{n-gramů} se liší od běžného výpočtu precision tím,
  že je místo počtu kandidátů potvrzených n-gramů použit počet potvrzených n-gramů (viz definice v \ref{chap:motivation}.~Kapitole).

$$ \text{MODIFIED PRECISION} = \frac{\lvert \lbrace \text{potvrzené \mbox{n-gramy}} \rbrace \rvert }{ \lvert \lbrace \text{ n-gramy ze strojového překladu } \rbrace \rvert } $$

Tímto způsobem je možné spočítat modified precision pro libovolné délky n-gramů.
Avšak při výpočtu metriky BLEU se počítá pouze s \mbox{1-gramy}, \mbox{2-gramy}, \mbox{3-gramy} a \mbox{4-gramy}.
Modified precision pro jednotlivé délky n-gramů jsou pak zkombinovány pomocí geometrického průměru.

Aby bylo zaručeno,
  že překlad bude mít podobnou délku jako reference,
  používá se \textbf{brevity penalty},
  která zhoršuje skóre větám, které jsou kratší než reference.
Věty, které jsou delší než reference,
  nemusí být takto postihovány,
  protože postih za rozdíl v délkach vět je již zahrnut ve výpočtu modified precision.

$$
\text{BREVITY PENALTY} = \left\{
	\begin{array}{l l}
		1 & \quad \text{reference je kratší než překlad} \\
		e^{(1-r/t)} & \quad \text{reference je delší než překlad}
	\end{array}
\right.
$$

Metrika BLEU se pak spočítá pomocí následujícího vzorečku:

$$ \text{BLEU} = \text{BREVITY PENALTY} \sqrt[4]{\prod_{n=1}^{4} \frac{\lvert \lbrace \text{potvrzené \mbox{n-gramy}} \rbrace \rvert }{ \lvert \lbrace \text{ n-gramy ze strojového překladu } \rbrace \rvert }} $$


\section{BLEU${}_S$}
Aby bylo možné počítat metriku BLEU i pro jednotlivé věty,
  musí být vyřešena situace,
  kdy se v~některých větách nemusí vyskytovat žádné potvrzené \mbox{1-gramy}, \mbox{2-gramy}, \mbox{3-gramy} nebo \mbox{4-gramy}.
V~této situaci by výsledná metrika těchto vět byla rovna nule,
  i když by se v~nich nějaký potvrzený \mbox{n-gram} nacházel.
Tento problém řeší vylepšení metriky BLEU -- metrika BLEU${}_S$. %% přidat citaci
Ta připočítává +1 ke všem \mbox{n-gramům} delším než jedna.
Tím pádem můžeme spočítat metriku i pro věty,
  které nemají potvrzené \mbox{n-gramy} libovolné délky.
Zároveň dokážeme ohodnotit úplně špatný překlad nulovým skóre,
  protože 1-gramy vyhlazovány nejsou.

Skript mteval-13a.pl, %% přidat citaci
  vytvořený americkým Národním institutem pro standardizaci a technologie NIST,\footnote{http://www.nist.gov}
  používá jiný způsob vyhlazování.
Místo přičítání +1 ke všem \mbox{n-gramům} má speciální vzoreček pro počítání precision u~chybějících potvrzených \mbox{n-gramů}.
Pokud existuje nějaký potvrzený \mbox{n-gram} délky l,
  je použit normální vzorec pro výpočet modified precision.
V případě, že se v překladu nenachází žádný potvrzený \mbox{n-gram} délky l,
  je zafixována tato délka jako k
  a pro všechny délky větší nebo rovné l je použit vzorec:

$$\frac{1}{2^{l-k+1} \cdot \lvert \lbrace \text{ n-gramy ze strojového překladu } \rbrace \rvert }$$

Rozdíl obou metrik je možné demonstrovat na větě obsahující 4 slova,
  v níž se nachází jeden potvrzený 2-gram
  (z~čehož plyne, že obsahuje i dva potvrzené 1-gramy).

\begin{tabular}{| l | c | c || c | c |}
\hline
& & & \multicolumn{2}{c|}{PRECISION} \\
\cline{4-5}
délka & počet potvrzených & celkový počet & BLEU${}_S$ & mteval \\
\hline
1-gram & 2 & 4 & $\frac{2}{4} = 0.50$ & $\frac{2}{4} = 0.50$ \\
2-gram & 1 & 3 & $\frac{1+1}{3+1} = 0.50$ & $\frac{1}{3} \approx 0.33$ \\
3-gram & 0 & 2 & $\frac{0+1}{2+1} \approx 0.33$ & $\frac{1}{2^1 \cdot 2} = 0.25$ \\
4-gram & 0 & 1 & $\frac{0+1}{1+1} = 0.50$ & $\frac{1}{2^2 \cdot 1} = 0.25$ \\
\hline \hline 
\multicolumn{3}{ |r| }{bleu} & $\sqrt[4]{\frac{1}{2^3 3}}$ & $\sqrt[4]{\frac{1}{2^5 3}}$ \\
\hline
\end{tabular}

\bigskip

To, že se způsoby vyhlazování liší,
  ničemu nevadí,
  protože obě metriky ve většině případů dokáží rozpoznat lepší překlad od horšího.

V nástroji \mbox{MT-ComparEval} bylo použito vyhlazování BLEU${}_S$.

\section{Potvrzené \mbox{n-gramy}}
Další metrikou, kterou lze použít k řazení vět, je celkový počet potvrzených n-gramů.
Problémem této metriky je, 
  že v~delších větách může být více potvrzených \mbox{n-gramů}.
Dlouhé věty tedy budou předcházet kratším větám,
  u~kterých mohlo dojít k většímu zlepšení kvality překladu než u dlouhých vět.

\section{Recall}
Při výpočtu BLEU se počítá modified precision \mbox{n-gramů} ze strojového překladu.
Pokud se místo \mbox{n-gramů} ze strojového překladu použijí \mbox{n-gramy} z~referenčního překladu,
  vyjde metrika \textbf{Recall},
  která určuje s~jakou pravděpodobností se nachazí \mbox{n-gram} z~referenčního překladu i v~překladu strojovém.
$$ RECALL = \prod_{l=1}^{4} \frac{ \lvert \text{potvrzené \mbox{n-gramy} délky l} \rvert }{ \lvert \text{referenční \mbox{n-gramy} délky l} \rvert } $$

Nicméně i Recall má své problémy.
Strojové překlady,
  které jsou výrazně delší než překlady referenční,
  by mohly mít vysokou hodnotu Recall,
  ale i tak by se jednalo o~špatné překlady,
  protože by obsahovaly mnoho nadbytečných slov. 
Tento problém řeší metrika F-Measure,
  která bude vysvětlena v~následující části.

\section{F-Measure}
Metrika F-Measure kombinuje Recall i Precision,
  čímž zajišťuje, 
  že zbytečně dlouhé překlady budou mít horší výsledky.

$$ \text{F-MEASURE} = 2 \cdot \frac{\text{MODIFIED PRECISION} \cdot \text{RECALL}}{\text{MODIFIED PRECISION} + \text{RECALL}} $$


\section{Rozdělení rozdílů hodnot metrik ve větách}
Ve webovém rozhraní nástroje \mbox{MT-ComparEval} se nachází graf,
  který znázorňuje rozdělení rozdílů hodnot metrik ve větách porovnávaných systémů.
Z tohoto grafu je patrné, kolik překladů vět bylo zlepšeno a jak moc byl daný překlad zlepšen.
To samé lze z tohoto grafu zjistit pro věty, jejichž překlad byl zhoršen.

\section{Párový bootstrap resampling}
Pokud se při porovnání hodnoty metrik spočtených na celých dokumentech příliš neliší,
  není možné tvrdit, že překlad s vyšším skóre je automaticky lepší.
Aby bylo možné spolehlivě prohlásit, že překlad s vyšším skóre je lepší než překlad s nižším skóre,
  je nutné ověřit, že rozdíl mezi těmito hodnotami je signifikantní.
K tomuto účelu se používá metoda \textbf{Paired bootstrap resampling}. %% citace
  při které jsou vytvořeny uv{nové} vzorky náhodným výběrem vět (s opakováním) z překladu.
Pro každý takto získaný vzorek je spočtena metrika a z těchto výsledků je vybrán 95\% interval spolehlivosti.
Z tohoto intervalu spolehlivosti lze určit, jestli je daný překlad signifikantně lepší, signifikantně horší nebo není signifikatně ani lepší ani horší.

V nástroji \mbox{MT-ComparEval} se nachází i graf, který zobrazuje výsledky rozdílů metrik získaných během paired bootstrap resamplingu.



